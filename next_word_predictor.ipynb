{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading The Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1i5Edq2QVGC"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "Bqj7N24RQVCb",
    "outputId": "7d055393-9b4b-4be6-e2a7-3045caeb6a3a"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRXi4yNAQU33"
   },
   "outputs": [],
   "source": [
    "!rm -f ~/.kaggle            # remove if it was a file before\n",
    "!mkdir -p ~/.kaggle         # make directory\n",
    "!cp kaggle.json ~/.kaggle/  # copy your uploaded kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json  # secure permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDbkiCBAQU0Z",
    "outputId": "4e397183-e208-43e7-c2fb-d1d8f533fecc"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d dorianlazar/medium-articles-dataset -p /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Co6Fk8rAQUxv",
    "outputId": "bcc75e0f-1d11-4921-be14-ff2640291bfe"
   },
   "outputs": [],
   "source": [
    "!unzip -o /content/medium-articles-dataset.zip -d /content/medium_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imported The Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRatkSrkQUuV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import  torch.nn as nn\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "4j6n9p2KQUrS",
    "outputId": "e4e5972e-d71b-4a2c-c75e-443092d5b918"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/medium_data/medium_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I only need the title columns for for this project and i will just preprocess the data i am not going to do any  data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckGupLC-QUom",
    "outputId": "5e994dfd-f422-405f-861b-5cd345dbf2e7"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4qIoDPtQUll"
   },
   "outputs": [],
   "source": [
    "document = \"\\n\".join(df[\"title\"].dropna().astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "FAEi8DbVQUin",
    "outputId": "f725f8b9-b914-483b-f8ac-32e39a575485"
   },
   "outputs": [],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZBq_CcGTNMk",
    "outputId": "64db4e4c-e304-4849-e772-b650808eaee9"
   },
   "outputs": [],
   "source": [
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jItOs2zrTNJY",
    "outputId": "24b4e9c3-1fd0-4ede-d2ae-401a41b321c6"
   },
   "outputs": [],
   "source": [
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFS6qoX7TNGi"
   },
   "outputs": [],
   "source": [
    "tokens = word_tokenize(document.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBzOGJp8TND4",
    "outputId": "70f6e246-9820-4dee-9090-3673d965b3c1"
   },
   "outputs": [],
   "source": [
    "tokens[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISevT411TNBU",
    "outputId": "0f14392f-bf76-43db-f1f2-e80202724dbe"
   },
   "outputs": [],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-JGNv5LTM_M",
    "outputId": "a6883109-5333-4faf-fd55-b17e705b95ec"
   },
   "outputs": [],
   "source": [
    "vocab = {'<unk>' : 0}\n",
    "for token in Counter(tokens):\n",
    "  if token not in vocab:\n",
    "    vocab[token] = len(vocab)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ny67k9fcXChC",
    "outputId": "19eac772-21d4-455b-d29e-c6041ba90b50"
   },
   "outputs": [],
   "source": [
    "Counter(vocab).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhV6RmkZTM3y"
   },
   "outputs": [],
   "source": [
    "input_sequences = document.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BShTV4gPYMA9",
    "outputId": "0e98963e-575a-4fff-b6ce-05c65215f397"
   },
   "outputs": [],
   "source": [
    "input_sequences[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PyJmjEeYL9a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def text_to_indices(sentence, vocab):\n",
    "\n",
    "  numerical_sentence = []\n",
    "\n",
    "  for token in sentence:\n",
    "    if token in vocab:\n",
    "      numerical_sentence.append(vocab[token])\n",
    "    else:\n",
    "      numerical_sentence.append(vocab['<unk>'])\n",
    "\n",
    "  return numerical_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDmXi95LYL6l"
   },
   "outputs": [],
   "source": [
    "input_numerical_sentences = []\n",
    "\n",
    "for sentence in input_sequences:\n",
    "  input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKrrPn4rYL3o",
    "outputId": "5ab505e6-61ad-4bc1-caf5-ee39ad485a16"
   },
   "outputs": [],
   "source": [
    "input_numerical_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEqNWYEPYL1N",
    "outputId": "c6b8fc59-4393-4b4b-fafe-3af140588ea8"
   },
   "outputs": [],
   "source": [
    "len(input_numerical_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EY5HPdR0YLx5"
   },
   "outputs": [],
   "source": [
    "training_sequence = []\n",
    "for sentence in input_numerical_sentences:\n",
    "\n",
    "  for i in range(1, len(sentence)):\n",
    "    training_sequence.append(sentence[:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3vw5iEwYLut",
    "outputId": "b141f7ea-716e-41c8-9b8a-e411d8e78568"
   },
   "outputs": [],
   "source": [
    "training_sequence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFdW1k47cQkg",
    "outputId": "e07c4a88-59cc-441b-fe36-9f6d2b5dcdad"
   },
   "outputs": [],
   "source": [
    "len(training_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Qk4hutmcQhC",
    "outputId": "a7bd92fe-51b5-4b69-fed3-6204ff12720f"
   },
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for sequence in training_sequence:\n",
    "  len_list.append(len(sequence))\n",
    "\n",
    "max(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_z6Vu3PKh4y6",
    "outputId": "c036afc8-5688-47c4-c636-634a8520bd17"
   },
   "outputs": [],
   "source": [
    "len(training_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8Ns80aVcQd-"
   },
   "outputs": [],
   "source": [
    "padded_training_sequence = []\n",
    "for sequence in training_sequence:\n",
    "\n",
    "  padded_training_sequence.append([0]*(max(len_list) - len(sequence)) + sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHrrN0VdgMCH",
    "outputId": "67ff2984-de3d-4f4b-b78e-dfdba9b1c119"
   },
   "outputs": [],
   "source": [
    "len(padded_training_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iw3XaDtgL-q"
   },
   "outputs": [],
   "source": [
    "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lpJ0rx7CgL8T",
    "outputId": "5c5f1aed-2962-4fc1-f914-ccf04a79b2c2"
   },
   "outputs": [],
   "source": [
    "padded_training_sequence[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsLq69jugL5a"
   },
   "outputs": [],
   "source": [
    "X = padded_training_sequence[:, :-1]\n",
    "y = padded_training_sequence[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4-mKWauYLo6",
    "outputId": "fa49f255-71f7-42a7-db62-4d2d532dbf72"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZtYL4PKh8i8",
    "outputId": "475318dc-570e-422e-ab46-59889371624b"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPRMiOjYiKNI"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.X.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08-p9kUPiKJo"
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zfjFHd5fiKHG",
    "outputId": "b74fd567-ff6e-46e8-feb6-9bc993a5d4d7"
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVAdtwyqiKEg"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implimenting The LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_pbLq9hiKBg"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LSTMModel(nn.Module):\n",
    "\n",
    "  def __init__(self, vocab_size):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, 100)\n",
    "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
    "    self.fc = nn.Linear(150, vocab_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    embedded = self.embedding(x)\n",
    "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
    "    output = self.fc(final_hidden_state.squeeze(0))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Lg1-0Q3iJ-0"
   },
   "outputs": [],
   "source": [
    "model = LSTMModel(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YubXlyJliJ8J"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CA61O0Dsiqp-",
    "outputId": "2afbcc12-acd3-4282-a03d-008e1f093128"
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ggXZBG_iqmm"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCpPGWuFiqkF",
    "outputId": "61185703-fc32-4c1f-c8a5-3253b6cb2e89"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "  total_loss = 0\n",
    "  for batch_x, batch_y in dataloader:\n",
    "\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch_x)\n",
    "    loss = criterion(output, batch_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJeXoJz_iqhY"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def prediction(model, vocab, text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    tokenized_text = word_tokenize(text.lower())\n",
    "    numerical_text = text_to_indices(tokenized_text, vocab)\n",
    "\n",
    "    padded_text = torch.tensor([0] * (51 - len(numerical_text)) + numerical_text,\n",
    "                                dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    output = model(padded_text)\n",
    "    _, index = torch.max(output, dim=1)\n",
    "\n",
    "    predicted_token = list(vocab.keys())[index]\n",
    "    return predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSBUI93fp6y1",
    "outputId": "b8248a32-eb81-4253-9fa1-e8b867a93767"
   },
   "outputs": [],
   "source": [
    "num_tokens = 20\n",
    "input_text = \"A Step-by-Step Implementation of\"\n",
    "\n",
    "print(input_text, end=\" \")\n",
    "\n",
    "for i in range(num_tokens):\n",
    "    next_word = prediction(model, vocab, input_text)\n",
    "    print(next_word, end=\" \", flush=True)\n",
    "    input_text += \" \" + next_word\n",
    "    time.sleep(0.5)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RFPvY_Wq70K"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"vocab\": vocab,\n",
    "    \"max_length\": 51\n",
    "}, \"checkpoint.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
